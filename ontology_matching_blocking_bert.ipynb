{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1DOCjsiFMQyEkV88Ch66clwIGDBoqE5hx",
      "authorship_tag": "ABX9TyMhTfDP3jbwSJe8Ruo6GlCn"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(torch.cuda.get_device_name(0))\n",
        "print('Torch', torch.__version__, 'CUDA', torch.version.cuda)\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yJJdmH7PQWpD",
        "outputId": "2d675c5e-bacd-43af-9b3a-431dd6f07bd1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tesla T4\n",
            "Torch 1.12.0+cu113 CUDA 11.3\n",
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install dependencies and import libraries"
      ],
      "metadata": {
        "id": "W2pzp0oz7t5Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o0tZ2CmV7qvS",
        "outputId": "fabede13-af20-43af-eca0-c2e95d50a1d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.21.0)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.7/dist-packages (2.4.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.8.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from datasets) (3.0.0)\n",
            "Requirement already satisfied: dill<0.3.6 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.5.1)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (2022.7.0)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.18.0)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.13)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets) (3.8.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.25.11)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.3.0)\n",
            "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (0.13.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (21.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (6.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.7.2)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.1.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2022.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L1lf7pmKsB7o"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from transformers import AutoTokenizer, DataCollatorWithPadding, AutoModelForSequenceClassification, TrainingArguments, Trainer, DistilBertTokenizerFast\n",
        "from datasets import load_dataset\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocess data"
      ],
      "metadata": {
        "id": "PFprsYId77Y8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_path = 'drive/MyDrive/Colab Notebooks/ontology-matching/'\n",
        "property_mapping = pd.read_csv(base_path + \"gs_property.csv\", names= ['column','property', 'match'], header=None)\n",
        "property_mapping"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "wjpzH0EDwjA6",
        "outputId": "912021da-a908-4ff5-ceda-c635e5f6ebf1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                      column  \\\n",
              "0    68779923_1_3240042497463101224.csv~Col4   \n",
              "1    10630177_0_4831842476649004753.csv~Col2   \n",
              "2    78891639_0_3299957631631122948.csv~Col3   \n",
              "3    25404227_0_2240631045609013057.csv~Col3   \n",
              "4    71840765_0_6664391841933033844.csv~Col2   \n",
              "..                                       ...   \n",
              "327  47709681_0_4437772923903322343.csv~Col0   \n",
              "328  86627271_6_2239821927452848323.csv~Col2   \n",
              "329  21245481_0_8730460088443117515.csv~Col1   \n",
              "330   55027702_0_628532586316851176.csv~Col2   \n",
              "331  51741865_0_9203644246202164492.csv~Col2   \n",
              "\n",
              "                                        property  match  \n",
              "0     http://dbpedia.org/ontology/governmentType   True  \n",
              "1     http://www.w3.org/2000/01/rdf-schema#label   True  \n",
              "2    http://dbpedia.org/ontology/populationTotal   True  \n",
              "3           http://dbpedia.org/ontology/director   True  \n",
              "4          http://dbpedia.org/ontology/elevation   True  \n",
              "..                                           ...    ...  \n",
              "327   http://www.w3.org/2000/01/rdf-schema#label   True  \n",
              "328        http://dbpedia.org/ontology/areaTotal   True  \n",
              "329   http://www.w3.org/2000/01/rdf-schema#label   True  \n",
              "330        http://dbpedia.org/ontology/elevation   True  \n",
              "331  http://dbpedia.org/ontology/programmeFormat   True  \n",
              "\n",
              "[332 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-20f55542-3f14-4fca-8edd-85516cf4dc12\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>column</th>\n",
              "      <th>property</th>\n",
              "      <th>match</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>68779923_1_3240042497463101224.csv~Col4</td>\n",
              "      <td>http://dbpedia.org/ontology/governmentType</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10630177_0_4831842476649004753.csv~Col2</td>\n",
              "      <td>http://www.w3.org/2000/01/rdf-schema#label</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>78891639_0_3299957631631122948.csv~Col3</td>\n",
              "      <td>http://dbpedia.org/ontology/populationTotal</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>25404227_0_2240631045609013057.csv~Col3</td>\n",
              "      <td>http://dbpedia.org/ontology/director</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>71840765_0_6664391841933033844.csv~Col2</td>\n",
              "      <td>http://dbpedia.org/ontology/elevation</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>327</th>\n",
              "      <td>47709681_0_4437772923903322343.csv~Col0</td>\n",
              "      <td>http://www.w3.org/2000/01/rdf-schema#label</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>328</th>\n",
              "      <td>86627271_6_2239821927452848323.csv~Col2</td>\n",
              "      <td>http://dbpedia.org/ontology/areaTotal</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>329</th>\n",
              "      <td>21245481_0_8730460088443117515.csv~Col1</td>\n",
              "      <td>http://www.w3.org/2000/01/rdf-schema#label</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>330</th>\n",
              "      <td>55027702_0_628532586316851176.csv~Col2</td>\n",
              "      <td>http://dbpedia.org/ontology/elevation</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>331</th>\n",
              "      <td>51741865_0_9203644246202164492.csv~Col2</td>\n",
              "      <td>http://dbpedia.org/ontology/programmeFormat</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>332 rows Ã— 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-20f55542-3f14-4fca-8edd-85516cf4dc12')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-20f55542-3f14-4fca-8edd-85516cf4dc12 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-20f55542-3f14-4fca-8edd-85516cf4dc12');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "class PropertyIndex:\n",
        "  def __init__(self, persisted_file=None) -> None:\n",
        "      if persisted_file is None:\n",
        "        self.property_ids = {}\n",
        "        self.property_names = {}\n",
        "        self.counter = 0\n",
        "      else:\n",
        "        self.load(persisted_file)\n",
        "\n",
        "  def get_property_id(self, column_name):\n",
        "    if property not in self.property_ids:\n",
        "      self.property_ids[property] = self.counter\n",
        "      self.property_names[self.counter] = property\n",
        "      self.counter += 1\n",
        "    return self.property_ids[property]\n",
        "\n",
        "  def get_property_name(self, id):\n",
        "    return self.property_names.get(id)\n",
        "\n",
        "  def num_labels(self):\n",
        "    return self.counter + 1\n",
        "\n",
        "  def load(self, persisted_file):\n",
        "    with open(persisted_file, 'r') as f:\n",
        "      self.property_ids = json.load(f.readline())\n",
        "      self.property_names = json.load(f.readline())\n",
        "      self.counter = int(json.load(f.readline()))\n",
        "\n",
        "  def persist(self, filename):\n",
        "    id_mapping = json.dumps(self.property_ids)\n",
        "    name_mapping = json.dumps(self.property_names)\n",
        "    with open(filename, \"w\") as f:\n",
        "      f.write(id_mapping + \"\\n\")\n",
        "      f.write(name_mapping + \"\\n\")\n",
        "      f.write(str(self.counter) + \"\\n\")\n"
      ],
      "metadata": {
        "id": "rXmk-kq86OCt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_filename_and_col_index(str):\n",
        "  [filename, col] = str.split('~')\n",
        "  return filename, int(col[3:])"
      ],
      "metadata": {
        "id": "yb4J9I5uzSFw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "values = pd.DataFrame({'value': pd.Series(dtype='str'), 'property_id': pd.Series(dtype='int')})\n",
        "property_index = PropertyIndex()\n",
        "\n",
        "for index, row in property_mapping.iterrows():\n",
        "  column = row['column']\n",
        "  property = row['property']\n",
        "\n",
        "  property_id = property_index.get_property_id(property)\n",
        "\n",
        "  filename, col_index = extract_filename_and_col_index(column)\n",
        "  webtable = pd.read_csv(base_path + \"webtables/\" + filename, header=None)\n",
        "  colum_values = webtable.iloc[:, col_index]\n",
        "  colum_values.name = \"value\"\n",
        "  df = colum_values.to_frame()\n",
        "  df['property_id'] = df['value'].apply(lambda x: int(property_id))\n",
        "  values = pd.concat([values, df])\n",
        "\n",
        "values = values.dropna()\n",
        "\n",
        "train_texts = values[\"value\"].values.tolist()\n",
        "train_labels = values['property_id'].values.tolist()\n",
        "\n",
        "train_texts, test_texts, train_labels, test_labels = train_test_split(train_texts, train_labels, test_size=.2)\n",
        "print(f\"Train size: {len(train_texts)}, Test size: {len(test_texts)}\")\n",
        "\n",
        "property_index.persist(base_path + \"property_index.txt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oEohN5AuxaWA",
        "outputId": "9418d869-8d7e-4a18-fd87-81670be7c6ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train size: 33041, Test size: 8261\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a custom dataset"
      ],
      "metadata": {
        "id": "9hoSbdwf8e-b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class WebtableDataset(Dataset):\n",
        "  def __init__(self, encodings, labels, name):\n",
        "      super().__init__()\n",
        "      self.encodings = encodings\n",
        "      self.labels = labels\n",
        "      self.name = name\n",
        "\n",
        "  def __len__(self):\n",
        "      return len(self.labels)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "      item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "      item['labels'] = torch.tensor(self.labels[idx])\n",
        "      return item\n"
      ],
      "metadata": {
        "id": "lTOE8Bc-8eAX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the BERT model"
      ],
      "metadata": {
        "id": "KxcyOhE87-hd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BZuylSeQLb37",
        "outputId": "bd8cefd3-841c-446d-a506-762d2c4c908a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file https://huggingface.co/distilbert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/23454919702d26495337f3da04d1655c7ee010d5ec9d77bdb9e399e00302c0a1.91b885ab15d631bf9cee9dc9d25ece0afd932f2f5130eba28f2055b2220c0333\n",
            "Model config DistilBertConfig {\n",
            "  \"_name_or_path\": \"distilbert-base-uncased\",\n",
            "  \"activation\": \"gelu\",\n",
            "  \"architectures\": [\n",
            "    \"DistilBertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.1,\n",
            "  \"dim\": 768,\n",
            "  \"dropout\": 0.1,\n",
            "  \"hidden_dim\": 3072,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"distilbert\",\n",
            "  \"n_heads\": 12,\n",
            "  \"n_layers\": 6,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"qa_dropout\": 0.1,\n",
            "  \"seq_classif_dropout\": 0.2,\n",
            "  \"sinusoidal_pos_embds\": false,\n",
            "  \"tie_weights_\": true,\n",
            "  \"transformers_version\": \"4.20.1\",\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading file https://huggingface.co/distilbert-base-uncased/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/0e1bbfda7f63a99bb52e3915dcf10c3c92122b827d92eb2d34ce94ee79ba486c.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
            "loading file https://huggingface.co/distilbert-base-uncased/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/75abb59d7a06f4f640158a9bfcde005264e59e8d566781ab1415b139d2e4c603.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4\n",
            "loading file https://huggingface.co/distilbert-base-uncased/resolve/main/added_tokens.json from cache at None\n",
            "loading file https://huggingface.co/distilbert-base-uncased/resolve/main/special_tokens_map.json from cache at None\n",
            "loading file https://huggingface.co/distilbert-base-uncased/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/8c8624b8ac8aa99c60c912161f8332de003484428c47906d7ff7eb7f73eecdbb.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79\n",
            "loading configuration file https://huggingface.co/distilbert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/23454919702d26495337f3da04d1655c7ee010d5ec9d77bdb9e399e00302c0a1.91b885ab15d631bf9cee9dc9d25ece0afd932f2f5130eba28f2055b2220c0333\n",
            "Model config DistilBertConfig {\n",
            "  \"_name_or_path\": \"distilbert-base-uncased\",\n",
            "  \"activation\": \"gelu\",\n",
            "  \"architectures\": [\n",
            "    \"DistilBertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.1,\n",
            "  \"dim\": 768,\n",
            "  \"dropout\": 0.1,\n",
            "  \"hidden_dim\": 3072,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"distilbert\",\n",
            "  \"n_heads\": 12,\n",
            "  \"n_layers\": 6,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"qa_dropout\": 0.1,\n",
            "  \"seq_classif_dropout\": 0.2,\n",
            "  \"sinusoidal_pos_embds\": false,\n",
            "  \"tie_weights_\": true,\n",
            "  \"transformers_version\": \"4.20.1\",\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_encodings = tokenizer(train_texts, truncation=True, padding=True)\n",
        "test_encodings = tokenizer(test_texts, truncation=True, padding=True)\n",
        "\n",
        "training_data = WebtableDataset(train_encodings, train_labels, 'train')\n",
        "test_data = WebtableDataset(test_encodings, test_labels, 'test')"
      ],
      "metadata": {
        "id": "Hcv-AhBMznre"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(pred):\n",
        "  labels = pred.label_ids\n",
        "  preds = pred.predictions.argmax(-1)\n",
        "  # calculate accuracy using sklearn's function\n",
        "  acc = accuracy_score(labels, preds)\n",
        "  return {\n",
        "      'accuracy': acc,\n",
        "  }"
      ],
      "metadata": {
        "id": "hiBwpf6HZWbO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_function(text):\n",
        "    return tokenizer(text, truncation=True)\n",
        "\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=property_index.num_labels())\n",
        "model = model\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=base_path + \"results\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=5,\n",
        "    weight_decay=0.01,\n",
        "    load_best_model_at_end=True,\n",
        "    evaluation_strategy=\"steps\"\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=training_data,\n",
        "    eval_dataset=test_data,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "results = trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "bjq1_HXv8Le_",
        "outputId": "5c93b506-ba12-487a-e97c-2e9816f197a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file https://huggingface.co/distilbert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/23454919702d26495337f3da04d1655c7ee010d5ec9d77bdb9e399e00302c0a1.91b885ab15d631bf9cee9dc9d25ece0afd932f2f5130eba28f2055b2220c0333\n",
            "Model config DistilBertConfig {\n",
            "  \"_name_or_path\": \"distilbert-base-uncased\",\n",
            "  \"activation\": \"gelu\",\n",
            "  \"architectures\": [\n",
            "    \"DistilBertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.1,\n",
            "  \"dim\": 768,\n",
            "  \"dropout\": 0.1,\n",
            "  \"hidden_dim\": 3072,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\",\n",
            "    \"3\": \"LABEL_3\",\n",
            "    \"4\": \"LABEL_4\",\n",
            "    \"5\": \"LABEL_5\",\n",
            "    \"6\": \"LABEL_6\",\n",
            "    \"7\": \"LABEL_7\",\n",
            "    \"8\": \"LABEL_8\",\n",
            "    \"9\": \"LABEL_9\",\n",
            "    \"10\": \"LABEL_10\",\n",
            "    \"11\": \"LABEL_11\",\n",
            "    \"12\": \"LABEL_12\",\n",
            "    \"13\": \"LABEL_13\",\n",
            "    \"14\": \"LABEL_14\",\n",
            "    \"15\": \"LABEL_15\",\n",
            "    \"16\": \"LABEL_16\",\n",
            "    \"17\": \"LABEL_17\",\n",
            "    \"18\": \"LABEL_18\",\n",
            "    \"19\": \"LABEL_19\",\n",
            "    \"20\": \"LABEL_20\",\n",
            "    \"21\": \"LABEL_21\",\n",
            "    \"22\": \"LABEL_22\",\n",
            "    \"23\": \"LABEL_23\",\n",
            "    \"24\": \"LABEL_24\",\n",
            "    \"25\": \"LABEL_25\",\n",
            "    \"26\": \"LABEL_26\",\n",
            "    \"27\": \"LABEL_27\",\n",
            "    \"28\": \"LABEL_28\",\n",
            "    \"29\": \"LABEL_29\",\n",
            "    \"30\": \"LABEL_30\",\n",
            "    \"31\": \"LABEL_31\",\n",
            "    \"32\": \"LABEL_32\",\n",
            "    \"33\": \"LABEL_33\",\n",
            "    \"34\": \"LABEL_34\",\n",
            "    \"35\": \"LABEL_35\",\n",
            "    \"36\": \"LABEL_36\",\n",
            "    \"37\": \"LABEL_37\",\n",
            "    \"38\": \"LABEL_38\",\n",
            "    \"39\": \"LABEL_39\",\n",
            "    \"40\": \"LABEL_40\",\n",
            "    \"41\": \"LABEL_41\",\n",
            "    \"42\": \"LABEL_42\",\n",
            "    \"43\": \"LABEL_43\",\n",
            "    \"44\": \"LABEL_44\",\n",
            "    \"45\": \"LABEL_45\",\n",
            "    \"46\": \"LABEL_46\",\n",
            "    \"47\": \"LABEL_47\",\n",
            "    \"48\": \"LABEL_48\",\n",
            "    \"49\": \"LABEL_49\",\n",
            "    \"50\": \"LABEL_50\",\n",
            "    \"51\": \"LABEL_51\",\n",
            "    \"52\": \"LABEL_52\",\n",
            "    \"53\": \"LABEL_53\",\n",
            "    \"54\": \"LABEL_54\",\n",
            "    \"55\": \"LABEL_55\",\n",
            "    \"56\": \"LABEL_56\",\n",
            "    \"57\": \"LABEL_57\",\n",
            "    \"58\": \"LABEL_58\",\n",
            "    \"59\": \"LABEL_59\",\n",
            "    \"60\": \"LABEL_60\",\n",
            "    \"61\": \"LABEL_61\",\n",
            "    \"62\": \"LABEL_62\",\n",
            "    \"63\": \"LABEL_63\",\n",
            "    \"64\": \"LABEL_64\",\n",
            "    \"65\": \"LABEL_65\",\n",
            "    \"66\": \"LABEL_66\",\n",
            "    \"67\": \"LABEL_67\",\n",
            "    \"68\": \"LABEL_68\",\n",
            "    \"69\": \"LABEL_69\",\n",
            "    \"70\": \"LABEL_70\",\n",
            "    \"71\": \"LABEL_71\",\n",
            "    \"72\": \"LABEL_72\",\n",
            "    \"73\": \"LABEL_73\",\n",
            "    \"74\": \"LABEL_74\",\n",
            "    \"75\": \"LABEL_75\",\n",
            "    \"76\": \"LABEL_76\",\n",
            "    \"77\": \"LABEL_77\",\n",
            "    \"78\": \"LABEL_78\",\n",
            "    \"79\": \"LABEL_79\",\n",
            "    \"80\": \"LABEL_80\",\n",
            "    \"81\": \"LABEL_81\",\n",
            "    \"82\": \"LABEL_82\",\n",
            "    \"83\": \"LABEL_83\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_10\": 10,\n",
            "    \"LABEL_11\": 11,\n",
            "    \"LABEL_12\": 12,\n",
            "    \"LABEL_13\": 13,\n",
            "    \"LABEL_14\": 14,\n",
            "    \"LABEL_15\": 15,\n",
            "    \"LABEL_16\": 16,\n",
            "    \"LABEL_17\": 17,\n",
            "    \"LABEL_18\": 18,\n",
            "    \"LABEL_19\": 19,\n",
            "    \"LABEL_2\": 2,\n",
            "    \"LABEL_20\": 20,\n",
            "    \"LABEL_21\": 21,\n",
            "    \"LABEL_22\": 22,\n",
            "    \"LABEL_23\": 23,\n",
            "    \"LABEL_24\": 24,\n",
            "    \"LABEL_25\": 25,\n",
            "    \"LABEL_26\": 26,\n",
            "    \"LABEL_27\": 27,\n",
            "    \"LABEL_28\": 28,\n",
            "    \"LABEL_29\": 29,\n",
            "    \"LABEL_3\": 3,\n",
            "    \"LABEL_30\": 30,\n",
            "    \"LABEL_31\": 31,\n",
            "    \"LABEL_32\": 32,\n",
            "    \"LABEL_33\": 33,\n",
            "    \"LABEL_34\": 34,\n",
            "    \"LABEL_35\": 35,\n",
            "    \"LABEL_36\": 36,\n",
            "    \"LABEL_37\": 37,\n",
            "    \"LABEL_38\": 38,\n",
            "    \"LABEL_39\": 39,\n",
            "    \"LABEL_4\": 4,\n",
            "    \"LABEL_40\": 40,\n",
            "    \"LABEL_41\": 41,\n",
            "    \"LABEL_42\": 42,\n",
            "    \"LABEL_43\": 43,\n",
            "    \"LABEL_44\": 44,\n",
            "    \"LABEL_45\": 45,\n",
            "    \"LABEL_46\": 46,\n",
            "    \"LABEL_47\": 47,\n",
            "    \"LABEL_48\": 48,\n",
            "    \"LABEL_49\": 49,\n",
            "    \"LABEL_5\": 5,\n",
            "    \"LABEL_50\": 50,\n",
            "    \"LABEL_51\": 51,\n",
            "    \"LABEL_52\": 52,\n",
            "    \"LABEL_53\": 53,\n",
            "    \"LABEL_54\": 54,\n",
            "    \"LABEL_55\": 55,\n",
            "    \"LABEL_56\": 56,\n",
            "    \"LABEL_57\": 57,\n",
            "    \"LABEL_58\": 58,\n",
            "    \"LABEL_59\": 59,\n",
            "    \"LABEL_6\": 6,\n",
            "    \"LABEL_60\": 60,\n",
            "    \"LABEL_61\": 61,\n",
            "    \"LABEL_62\": 62,\n",
            "    \"LABEL_63\": 63,\n",
            "    \"LABEL_64\": 64,\n",
            "    \"LABEL_65\": 65,\n",
            "    \"LABEL_66\": 66,\n",
            "    \"LABEL_67\": 67,\n",
            "    \"LABEL_68\": 68,\n",
            "    \"LABEL_69\": 69,\n",
            "    \"LABEL_7\": 7,\n",
            "    \"LABEL_70\": 70,\n",
            "    \"LABEL_71\": 71,\n",
            "    \"LABEL_72\": 72,\n",
            "    \"LABEL_73\": 73,\n",
            "    \"LABEL_74\": 74,\n",
            "    \"LABEL_75\": 75,\n",
            "    \"LABEL_76\": 76,\n",
            "    \"LABEL_77\": 77,\n",
            "    \"LABEL_78\": 78,\n",
            "    \"LABEL_79\": 79,\n",
            "    \"LABEL_8\": 8,\n",
            "    \"LABEL_80\": 80,\n",
            "    \"LABEL_81\": 81,\n",
            "    \"LABEL_82\": 82,\n",
            "    \"LABEL_83\": 83,\n",
            "    \"LABEL_9\": 9\n",
            "  },\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"distilbert\",\n",
            "  \"n_heads\": 12,\n",
            "  \"n_layers\": 6,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"qa_dropout\": 0.1,\n",
            "  \"seq_classif_dropout\": 0.2,\n",
            "  \"sinusoidal_pos_embds\": false,\n",
            "  \"tie_weights_\": true,\n",
            "  \"transformers_version\": \"4.20.1\",\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading weights file https://huggingface.co/distilbert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/9c169103d7e5a73936dd2b627e42851bec0831212b677c637033ee4bce9ab5ee.126183e36667471617ae2f0835fab707baa54b731f991507ebbb55ea85adb12a\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_projector.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias']\n",
            "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'classifier.weight', 'classifier.bias', 'pre_classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "using `logging_steps` to initialize `eval_steps` to 500\n",
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 33041\n",
            "  Num Epochs = 5\n",
            "  Instantaneous batch size per device = 16\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 10330\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='10330' max='10330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [10330/10330 22:47, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>2.310300</td>\n",
              "      <td>1.470279</td>\n",
              "      <td>0.673889</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>1.280800</td>\n",
              "      <td>1.011921</td>\n",
              "      <td>0.736230</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.965200</td>\n",
              "      <td>0.854922</td>\n",
              "      <td>0.764677</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.820300</td>\n",
              "      <td>0.746403</td>\n",
              "      <td>0.784530</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.678400</td>\n",
              "      <td>0.704161</td>\n",
              "      <td>0.790340</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.645000</td>\n",
              "      <td>0.667168</td>\n",
              "      <td>0.794940</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3500</td>\n",
              "      <td>0.611000</td>\n",
              "      <td>0.636555</td>\n",
              "      <td>0.804261</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>0.581200</td>\n",
              "      <td>0.622814</td>\n",
              "      <td>0.808498</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4500</td>\n",
              "      <td>0.523700</td>\n",
              "      <td>0.602059</td>\n",
              "      <td>0.814913</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>0.482900</td>\n",
              "      <td>0.595967</td>\n",
              "      <td>0.813340</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5500</td>\n",
              "      <td>0.487000</td>\n",
              "      <td>0.594315</td>\n",
              "      <td>0.815640</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6000</td>\n",
              "      <td>0.484600</td>\n",
              "      <td>0.574516</td>\n",
              "      <td>0.819392</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6500</td>\n",
              "      <td>0.439400</td>\n",
              "      <td>0.588359</td>\n",
              "      <td>0.819150</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7000</td>\n",
              "      <td>0.416500</td>\n",
              "      <td>0.585551</td>\n",
              "      <td>0.820361</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7500</td>\n",
              "      <td>0.428700</td>\n",
              "      <td>0.582123</td>\n",
              "      <td>0.820845</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8000</td>\n",
              "      <td>0.401300</td>\n",
              "      <td>0.580230</td>\n",
              "      <td>0.823750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8500</td>\n",
              "      <td>0.383000</td>\n",
              "      <td>0.579305</td>\n",
              "      <td>0.826897</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9000</td>\n",
              "      <td>0.370800</td>\n",
              "      <td>0.584958</td>\n",
              "      <td>0.825203</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9500</td>\n",
              "      <td>0.381900</td>\n",
              "      <td>0.583670</td>\n",
              "      <td>0.824598</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10000</td>\n",
              "      <td>0.369500</td>\n",
              "      <td>0.578147</td>\n",
              "      <td>0.824598</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 8261\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to drive/MyDrive/Colab Notebooks/ontology-matching/results/checkpoint-500\n",
            "Configuration saved in drive/MyDrive/Colab Notebooks/ontology-matching/results/checkpoint-500/config.json\n",
            "Model weights saved in drive/MyDrive/Colab Notebooks/ontology-matching/results/checkpoint-500/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 8261\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to drive/MyDrive/Colab Notebooks/ontology-matching/results/checkpoint-1000\n",
            "Configuration saved in drive/MyDrive/Colab Notebooks/ontology-matching/results/checkpoint-1000/config.json\n",
            "Model weights saved in drive/MyDrive/Colab Notebooks/ontology-matching/results/checkpoint-1000/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 8261\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to drive/MyDrive/Colab Notebooks/ontology-matching/results/checkpoint-1500\n",
            "Configuration saved in drive/MyDrive/Colab Notebooks/ontology-matching/results/checkpoint-1500/config.json\n",
            "Model weights saved in drive/MyDrive/Colab Notebooks/ontology-matching/results/checkpoint-1500/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 8261\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to drive/MyDrive/Colab Notebooks/ontology-matching/results/checkpoint-2000\n",
            "Configuration saved in drive/MyDrive/Colab Notebooks/ontology-matching/results/checkpoint-2000/config.json\n",
            "Model weights saved in drive/MyDrive/Colab Notebooks/ontology-matching/results/checkpoint-2000/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 8261\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to drive/MyDrive/Colab Notebooks/ontology-matching/results/checkpoint-2500\n",
            "Configuration saved in drive/MyDrive/Colab Notebooks/ontology-matching/results/checkpoint-2500/config.json\n",
            "Model weights saved in drive/MyDrive/Colab Notebooks/ontology-matching/results/checkpoint-2500/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 8261\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to drive/MyDrive/Colab Notebooks/ontology-matching/results/checkpoint-3000\n",
            "Configuration saved in drive/MyDrive/Colab Notebooks/ontology-matching/results/checkpoint-3000/config.json\n",
            "Model weights saved in drive/MyDrive/Colab Notebooks/ontology-matching/results/checkpoint-3000/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 8261\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to drive/MyDrive/Colab Notebooks/ontology-matching/results/checkpoint-3500\n",
            "Configuration saved in drive/MyDrive/Colab Notebooks/ontology-matching/results/checkpoint-3500/config.json\n",
            "Model weights saved in drive/MyDrive/Colab Notebooks/ontology-matching/results/checkpoint-3500/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 8261\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to drive/MyDrive/Colab Notebooks/ontology-matching/results/checkpoint-4000\n",
            "Configuration saved in drive/MyDrive/Colab Notebooks/ontology-matching/results/checkpoint-4000/config.json\n",
            "Model weights saved in drive/MyDrive/Colab Notebooks/ontology-matching/results/checkpoint-4000/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 8261\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to drive/MyDrive/Colab Notebooks/ontology-matching/results/checkpoint-4500\n",
            "Configuration saved in drive/MyDrive/Colab Notebooks/ontology-matching/results/checkpoint-4500/config.json\n",
            "Model weights saved in drive/MyDrive/Colab Notebooks/ontology-matching/results/checkpoint-4500/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 8261\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to drive/MyDrive/Colab Notebooks/ontology-matching/results/checkpoint-5000\n",
            "Configuration saved in drive/MyDrive/Colab Notebooks/ontology-matching/results/checkpoint-5000/config.json\n",
            "Model weights saved in drive/MyDrive/Colab Notebooks/ontology-matching/results/checkpoint-5000/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 8261\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to drive/MyDrive/Colab Notebooks/ontology-matching/results/checkpoint-5500\n",
            "Configuration saved in drive/MyDrive/Colab Notebooks/ontology-matching/results/checkpoint-5500/config.json\n",
            "Model weights saved in drive/MyDrive/Colab Notebooks/ontology-matching/results/checkpoint-5500/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 8261\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to drive/MyDrive/Colab Notebooks/ontology-matching/results/checkpoint-6000\n",
            "Configuration saved in drive/MyDrive/Colab Notebooks/ontology-matching/results/checkpoint-6000/config.json\n",
            "Model weights saved in drive/MyDrive/Colab Notebooks/ontology-matching/results/checkpoint-6000/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 8261\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to drive/MyDrive/Colab Notebooks/ontology-matching/results/checkpoint-6500\n",
            "Configuration saved in drive/MyDrive/Colab Notebooks/ontology-matching/results/checkpoint-6500/config.json\n",
            "Model weights saved in drive/MyDrive/Colab Notebooks/ontology-matching/results/checkpoint-6500/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 8261\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to drive/MyDrive/Colab Notebooks/ontology-matching/results/checkpoint-7000\n",
            "Configuration saved in drive/MyDrive/Colab Notebooks/ontology-matching/results/checkpoint-7000/config.json\n",
            "Model weights saved in drive/MyDrive/Colab Notebooks/ontology-matching/results/checkpoint-7000/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 8261\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to drive/MyDrive/Colab Notebooks/ontology-matching/results/checkpoint-7500\n",
            "Configuration saved in drive/MyDrive/Colab Notebooks/ontology-matching/results/checkpoint-7500/config.json\n",
            "Model weights saved in drive/MyDrive/Colab Notebooks/ontology-matching/results/checkpoint-7500/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 8261\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to drive/MyDrive/Colab Notebooks/ontology-matching/results/checkpoint-8000\n",
            "Configuration saved in drive/MyDrive/Colab Notebooks/ontology-matching/results/checkpoint-8000/config.json\n",
            "Model weights saved in drive/MyDrive/Colab Notebooks/ontology-matching/results/checkpoint-8000/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 8261\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to drive/MyDrive/Colab Notebooks/ontology-matching/results/checkpoint-8500\n",
            "Configuration saved in drive/MyDrive/Colab Notebooks/ontology-matching/results/checkpoint-8500/config.json\n",
            "Model weights saved in drive/MyDrive/Colab Notebooks/ontology-matching/results/checkpoint-8500/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 8261\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to drive/MyDrive/Colab Notebooks/ontology-matching/results/checkpoint-9000\n",
            "Configuration saved in drive/MyDrive/Colab Notebooks/ontology-matching/results/checkpoint-9000/config.json\n",
            "Model weights saved in drive/MyDrive/Colab Notebooks/ontology-matching/results/checkpoint-9000/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 8261\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to drive/MyDrive/Colab Notebooks/ontology-matching/results/checkpoint-9500\n",
            "Configuration saved in drive/MyDrive/Colab Notebooks/ontology-matching/results/checkpoint-9500/config.json\n",
            "Model weights saved in drive/MyDrive/Colab Notebooks/ontology-matching/results/checkpoint-9500/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 8261\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to drive/MyDrive/Colab Notebooks/ontology-matching/results/checkpoint-10000\n",
            "Configuration saved in drive/MyDrive/Colab Notebooks/ontology-matching/results/checkpoint-10000/config.json\n",
            "Model weights saved in drive/MyDrive/Colab Notebooks/ontology-matching/results/checkpoint-10000/pytorch_model.bin\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from drive/MyDrive/Colab Notebooks/ontology-matching/results/checkpoint-6000 (score: 0.5745163559913635).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.evaluate()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "PktIu0IEk0TI",
        "outputId": "445631f1-266b-4784-b7e3-3ebad70032fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 8261\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='517' max='517' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [517/517 00:07]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'epoch': 5.0,\n",
              " 'eval_accuracy': 0.819392325384336,\n",
              " 'eval_loss': 0.5745163559913635,\n",
              " 'eval_runtime': 7.7766,\n",
              " 'eval_samples_per_second': 1062.293,\n",
              " 'eval_steps_per_second': 66.482}"
            ]
          },
          "metadata": {},
          "execution_count": 167
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z_9nOPg8t9bF",
        "outputId": "d9689ebc-d293-48dd-bc50-f358f7cbb7f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=10330, training_loss=0.6439428257457516, metrics={'train_runtime': 1367.5231, 'train_samples_per_second': 120.806, 'train_steps_per_second': 7.554, 'total_flos': 2482703496941040.0, 'train_loss': 0.6439428257457516, 'epoch': 5.0})"
            ]
          },
          "metadata": {},
          "execution_count": 172
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_prediction(text):\n",
        "    # prepare our text into tokenized sequence\n",
        "    inputs = tokenizer(text, padding=True, truncation=True, return_tensors=\"pt\").to(device)\n",
        "    # perform inference to our model\n",
        "    outputs = model(**inputs)\n",
        "    # get output probabilities by doing softmax\n",
        "    probs = outputs[0].softmax(1)\n",
        "    # executing argmax function to get the candidate label\n",
        "    probs, idxs = probs.topk(3)\n",
        "    # Unwrap the tensor\n",
        "    idxs = idxs.tolist()[0]\n",
        "    probs = probs.tolist()[0]\n",
        "    return [{'key': property_index.get_property_name(idxs[i]), 'prob': probs[i]} for i in range(len(idxs))]\n"
      ],
      "metadata": {
        "id": "gxt6f3eFYNvM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "\n",
        "get_prediction(\"germany\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y9H61wEtj7VW",
        "outputId": "cd565a34-49b6-450f-ed80-3c218fa81d65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'key': 'http://dbpedia.org/ontology/country', 'prob': 0.9325388073921204},\n",
              " {'key': 'http://www.w3.org/2000/01/rdf-schema#label',\n",
              "  'prob': 0.04996142536401749},\n",
              " {'key': 'http://dbpedia.org/ontology/collectionSize',\n",
              "  'prob': 0.004149576183408499}]"
            ]
          },
          "metadata": {},
          "execution_count": 174
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = base_path + \"ontology-matching-base-uncased\"\n",
        "model.save_pretrained(model_path)\n",
        "tokenizer.save_pretrained(model_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8FNV3gaQr6WC",
        "outputId": "073a3576-4c46-4a8d-8a74-b5a3b9ca2671"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Configuration saved in drive/MyDrive/Colab Notebooks/ontology-matching/ontology-matching-base-uncased/config.json\n",
            "Model weights saved in drive/MyDrive/Colab Notebooks/ontology-matching/ontology-matching-base-uncased/pytorch_model.bin\n",
            "tokenizer config file saved in drive/MyDrive/Colab Notebooks/ontology-matching/ontology-matching-base-uncased/tokenizer_config.json\n",
            "Special tokens file saved in drive/MyDrive/Colab Notebooks/ontology-matching/ontology-matching-base-uncased/special_tokens_map.json\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('drive/MyDrive/Colab Notebooks/ontology-matching/ontology-matching-base-uncased/tokenizer_config.json',\n",
              " 'drive/MyDrive/Colab Notebooks/ontology-matching/ontology-matching-base-uncased/special_tokens_map.json',\n",
              " 'drive/MyDrive/Colab Notebooks/ontology-matching/ontology-matching-base-uncased/vocab.txt',\n",
              " 'drive/MyDrive/Colab Notebooks/ontology-matching/ontology-matching-base-uncased/added_tokens.json',\n",
              " 'drive/MyDrive/Colab Notebooks/ontology-matching/ontology-matching-base-uncased/tokenizer.json')"
            ]
          },
          "metadata": {},
          "execution_count": 175
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NYXW9rvYxBJ4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}